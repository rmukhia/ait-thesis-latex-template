\setlength{\footskip}{8mm}

\chapter{Methodology}
\label{ch:methodology}

\textit{The different components of the system and how they work together are described in this chapter.}

\section{Hardware}

In the current system, the Mobius Maxi action cam, with a fish-eye lens is mounted on a rigid base. The PixHawk 2.4.8 flight controller, having IMU and a GPS module is attached to the rigid base. 


The data from both the devices are fed into a computer with an i7 CPU and 16 GB of RAM running Ubuntu 16.04. The PixHawk 2.4.8 has PX4 as its firmware. Both the devices are connected to the computer through the USB interface. In the Mobius cam, autofocus and auto white balance are turned off. 

The test rig is shown in Figure \ref{fig:rigsetup}. The test rig is mounted on top of radio controlled vehicle, the Tamiya Bullhead. 

\begin{figure}[htp]
	
	\centering
	\subfloat[]{%
	\includegraphics[width=.3\textwidth]{figures/rig}%
	}
	\subfloat[]{%
	\includegraphics[width=.3\textwidth]{figures/tamiya_bullhead}
	}
	\subfloat[]{%
	\includegraphics[width=.3\textwidth]{figures/rover-rig}
	}
	\caption[Test platform.]{\small 
		Test Platform. (a) Close up of the test setup. (b) Tamiya Bullhead. (c) Test rig mounted on top of the Tamiya Bullhead.}
	\label{fig:rigsetup}
	
\end{figure}


\section{Software}
Robot Operating System(ROS) Kinetic is running in the test machine. 
The software components are of the test machine are shown in Figure \ref{fig:rosgraph}.

\begin{figure} \label{fig:rosgraph}
	\centering
	\includegraphics[width=5in]{figures/rosgraph}
	\caption[ROS node tunning on test machine]{\small 
		ROS nodes running on test machine. }
\end{figure}

\begin{itemize}
	\item usb\_cam: Modified to support H264 streams.
	\item mavros: Communicates with PixHawk over the mavlink protocol.
	\item clips: A custom middleware that ensures there is at least one IMU data between each image frames
	\item LearnVIORB: Modified to publish pose, point clouds and tf information.
\end{itemize}

\subsection{usb\_cam node}
Mobius Maxi supports H264 hardware encoding. Video stream captured through this H264 stream is more smooth and supports higher framerates. The usb\_cam package directly captures video stream from USB cam, however, it does not support H264 streams.
The library \textbf{libavutils} which is used by this package has support for H264 streams. I added support for 'h264' pixel format parameter and a new color format parameter which can accept either 'yuv422p' and 'yuv420p to make the package stream H264 video feed from Mobius Maxi.
 
\subsection{mavros}
The test machine runs mavros to communicate with PixHawk Flight Controller. 
The PixHawk connection is shown as a serial port \textit{/dev/ttyACM0} on the test computer. The baud rate is chosen as \textit{921600}.
PX4 publishes coordinates in NED convention. Mavros automatically converts NED coordinated to ENU coordinates to use with ROS.

Time synchronization between PX4 and ROS is automatically done by \textbf{'sys\_time'} mavros plugin.
A timesync message $M$ is sent at a consistent frequency from the host system to FCU. The host system timestamps the message with the current time $t_s$. The remote system receives it and adds its timestamp $t_c$ to $M$ and replies back.
The offset between the host system and the remote system is calculated assuming round trip time for the message is equal in both ways.

\begin{equation}
offset = t_s + now - 2t_c
\end{equation}

The sigmoid function is a applied to interpolate $n$ observations to estimate the time offset. The estimate is further processed with an online exponential smoothing filter.
After the estimation has converged, the estimate is used until a maximum number of consecutive observations are received that is higher than a threshold deviation from the present estimate. In this case, the estimate is re-calculated with new $n$ observations.

\subsection{clips}
The IMU and camera are independently connected to the test computer and are not tightly bound. Although mavros does time synchronization, there should be some IMU measurement between two different image frames for VIORB to predict the next keyframe location. 
I implemented clips as middleware ROS package to ensure that at least there is one IMU measurement between two image frames.

\subsection{LearnVIORB}
LearnVIORB is a community developed implementation of Visual Inertial ORB SLAM \shortcite{DBLP:journals/corr/Mur-ArtalT16}. This package does not publish pose and point cloud in real time. Support for publishing pose, point cloud, and tf information as ROS topics were integrated as part of this special study. 
I referred to ORB\_SLAM2\_CUDA \url{https://github.com/hoangthien94/ORB\_SLAM2\_CUDA} which published these topics for implementation.

\subsection{PX4 firmware}
One of the requirements of VIORB is that the IMU measurements should be in hundreds of Hz. PX4 does not natively support more than 50 Hz. Consequently, to increase it I had to edit \textit{ROMFS/px4fmu\_common/init.d/rcS} file in the source code and recompile the firmware.
rcS file is executed during each bootup.

Ardupilot was another alternative, but it lacks support 200 Hz rates.

\begin{lstlisting}
	mavlink stream -d /dev/ttyACM0 -s ATTITUDE -r 200        
	mavlink stream -d /dev/ttyACM0 -s HIGHRES_IMU -r 200
\end{lstlisting}

\section{Calibration}
For a visual inertial SLAM system to work, the following parameters need to be calibrated beforehand.
 
\subsection{Camera intrinsic parameters}
The camera intrinsic parameters were calibrated with ROS camera\_calibration package. This package uses checkerboard to calculate ${\bf K}$ and the distortion parameters.

\subsection{IMU bias calculation} \label{section:imu_bias_calculation}
Stationary IMU data was recorded for a few hours. Then using \textbf{kalibr\_allan} package allan deviation was calculated and noise density and random walk was derived for accelerometer and gyroscope. 

\subsection{Camera IMU tranformation}
VIORB requires ${\bf T}_{CB}$, the camera to IMU transformation. The kalibr tool was used to find the transformation matrix ${\bf T}_{CB}$ and ${\bf T}_{BC}$, where $C$ is the camera's reference frame and $B$ is the IMU's reference frame. Kalibr uses apriltags or checkerboard pattern for calibration along with IMU bias calculation results. 

\section{Integration}
One of the requirements of VIORB SLAM is a configuration \textit{yaml} file which has camera IMU transformation ${\bf T}_{CB}$, camera intrinsic parameters ${\bf K}$ and distortion, ORB feature detector settings, IMU initialization time ,and camera and IMU drift. The \textit{yaml} file was created using the results of the above sections.

The IMU bias constants in \textit{src/IMU/imudata.cpp} was updated with the results of IMU bias calculation.


A single launch file in clips package starts usb\_cam, mavros, and clips. It publishes \textit{/imu0/data\_raw} and \textit{/cam0/image\_raw}. 

\begin{lstlisting}
<launch>                                                                                                               
	<node name="usb_cam" pkg="usb_cam" 
	type="usb_cam_node" output="screen>                                             
		<param name="video_device" value="/dev/video1" />                                                                  
		<param name="image_width" value="640" />                                                                           
		<param name="image_height" value="480" />                                                                          
		<param name="framerate" value="60" />                                                                              
		<param name="pixel_format" value="h264" />                                                                         
		<param name="color_format" value="yuv420p" />                                                                      
		<param name="camera_frame_id" value="usb_cam" />                                                                   
		<param name="io_method" value="mmap"/>                                                                             
	</node>                                                                                                              
	<include file="$(find mavros)/launch/px4.launch" />                                                                  
	<node name="clips" pkg="clips" 
	type="clips_node" respawn="false" output="screen"/>                                  
	<group ns="cam0">                                                                                                    
		<node name="image_proc" pkg="image_proc"
		type="image_proc" respawn="false" output="screen"/>                       
	</group>                                                                                                             
</launch
\end{lstlisting}

The \textit{/imu0/data\_raw} and \textit{/cam0/image\_raw} topics can either be directly subscribed by VIORB or it can be stored in a bag file. 

VIORB is launched using another launch file.
\begin{figure}
	\centering
	\includegraphics[width=5in]{figures/cloudpoint}
	\caption[Trial run]{\small 
		 A trial run which generates point cloud and pose in CS 203. }
\end{figure}

\FloatBarrier
